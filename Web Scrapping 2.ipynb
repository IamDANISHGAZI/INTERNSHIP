{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "5206c52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\danish gazi\\anaconda3\\lib\\site-packages (4.5.0)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\danish gazi\\anaconda3\\lib\\site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\users\\danish gazi\\anaconda3\\lib\\site-packages (from selenium) (1.26.9)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\danish gazi\\anaconda3\\lib\\site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\danish gazi\\anaconda3\\lib\\site-packages (from selenium) (2021.10.8)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\danish gazi\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\danish gazi\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: idna in c:\\users\\danish gazi\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\danish gazi\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\danish gazi\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\danish gazi\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.0.0rc9)\n",
      "Requirement already satisfied: outcome in c:\\users\\danish gazi\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\danish gazi\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: pycparser in c:\\users\\danish gazi\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\danish gazi\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\danish gazi\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\danish gazi\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "4353bb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all necessary libraries\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException,NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "9960e1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an instance driver by connecting it to our web driver\n",
    "driver=webdriver.Chrome(r\"D:\\webdriver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451e57a9",
   "metadata": {},
   "source": [
    "Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You \n",
    "have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 \n",
    "jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "2cd03e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sending URL to our Driver\n",
    "driver.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "ac074db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sending keys\n",
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input \")\n",
    "designation.send_keys('Data Analyst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "1c73efb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sending Location\n",
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys('Banglore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "8b890839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Searching location and keys\n",
    "search=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[6]\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "45e899b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty list for storing values\n",
    "job_title1=[]\n",
    "job_location1=[]\n",
    "company_name1=[]\n",
    "experience_required1=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "77d27e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3-6 Yrs',\n",
       " '2-5 Yrs',\n",
       " '6-8 Yrs',\n",
       " '1-6 Yrs',\n",
       " '1-2 Yrs',\n",
       " '1-2 Yrs',\n",
       " '4-8 Yrs',\n",
       " '3-6 Yrs',\n",
       " '5-10 Yrs',\n",
       " '2-7 Yrs']"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Searching all title on the page and store it in job title1 empty list\n",
    "title_tag=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tag[0:10]:\n",
    "    title=i.text\n",
    "    job_title1.append(title)\n",
    "job_title1[0:10]\n",
    "\n",
    "#Searching all location on the page and store it in job location1 empty list\n",
    "location_tag=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in location_tag[0:10]:\n",
    "    job_location1.append(i.text)\n",
    "job_location1[0:10]  \n",
    "\n",
    "\n",
    "#Searching all company name on the page and store it in company name1 empty list\n",
    "company_tag=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tag[0:10]:\n",
    "    company_name1.append(i.text)\n",
    "company_name1[0:10]\n",
    "\n",
    "#Searching all experience on the page and store it in experience required1 empty list\n",
    "experienced_tag=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "for i in experienced_tag:\n",
    "    experience_required1.append(i.text)\n",
    "experience_required1[0:10] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "076e02f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company name</th>\n",
       "      <th>Experience required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>Latentview</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Varite</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analytics and Interpretation Business Ana...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst - CRM Platform</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Chennai,...</td>\n",
       "      <td>Artech infosystem</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst - FinTech</td>\n",
       "      <td>Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst - FinTech</td>\n",
       "      <td>Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>What Digital Technologies Private Limited</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Freelancer - Data Analyst - Contractual Role</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>WEN</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lead Data Analyst (SQL &amp; Python) - US MNC (ana...</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru\\n(WFH du...</td>\n",
       "      <td>Aspyra HR Services</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>data analyst / data analytics - US MNC (analyt...</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru\\n(WFH du...</td>\n",
       "      <td>Aspyra HR Services</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Job title  \\\n",
       "1                                 Senior Data Analyst   \n",
       "2                                        Data Analyst   \n",
       "3   Data Analytics and Interpretation Business Ana...   \n",
       "4                         Data Analyst - CRM Platform   \n",
       "5                              Data Analyst - FinTech   \n",
       "6                              Data Analyst - FinTech   \n",
       "7                                        Data Analyst   \n",
       "8        Freelancer - Data Analyst - Contractual Role   \n",
       "9   Lead Data Analyst (SQL & Python) - US MNC (ana...   \n",
       "10  data analyst / data analytics - US MNC (analyt...   \n",
       "\n",
       "                                         Job Location  \\\n",
       "1                        Chennai, Bangalore/Bengaluru   \n",
       "2                                 Bangalore/Bengaluru   \n",
       "3                                 Bangalore/Bengaluru   \n",
       "4   Mumbai, Hyderabad/Secunderabad, Pune, Chennai,...   \n",
       "5   Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...   \n",
       "6   Kolkata, Mumbai, Hyderabad/Secunderabad, Pune,...   \n",
       "7                                 Bangalore/Bengaluru   \n",
       "8                                 Bangalore/Bengaluru   \n",
       "9   Gurgaon/Gurugram, Bangalore/Bengaluru\\n(WFH du...   \n",
       "10  Gurgaon/Gurugram, Bangalore/Bengaluru\\n(WFH du...   \n",
       "\n",
       "                                 Company name Experience required  \n",
       "1                                  Latentview             3-6 Yrs  \n",
       "2                                      Varite             2-5 Yrs  \n",
       "3                                   Accenture             6-8 Yrs  \n",
       "4                           Artech infosystem             1-6 Yrs  \n",
       "5                                Primo Hiring             1-2 Yrs  \n",
       "6                                Primo Hiring             1-2 Yrs  \n",
       "7   What Digital Technologies Private Limited             4-8 Yrs  \n",
       "8                                         WEN             3-6 Yrs  \n",
       "9                          Aspyra HR Services            5-10 Yrs  \n",
       "10                         Aspyra HR Services             2-7 Yrs  "
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Data Frame using Pandas\n",
    "df=pd.DataFrame({\"Job title\":job_title1[0:10],\"Job Location\":job_location1[0:10],\"Company name\":company_name1[0:10],\"Experience required\":experience_required1[0:10]})\n",
    "df.index+=1\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903d46d1",
   "metadata": {},
   "source": [
    "Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You \n",
    "have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "6b92fd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Driver by providing webdriver address\n",
    "driver=webdriver.Chrome(r\"D:\\webdriver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "3a99a6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sending request to url\n",
    "driver.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "f12b12ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sending Data Scientist using class name.\n",
    "desii=driver.find_element(By.CLASS_NAME,\"suggestor-input \")\n",
    "desii.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "a624606a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sending location using XPATH of location tab\n",
    "lo=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "lo.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "e2be0d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cicking on search button using XPATH of search button\n",
    "search=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[6]\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "533be5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty lists of titles location and company name to store values in it\n",
    "job_title2=[]\n",
    "job_location2=[]\n",
    "company_name2=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "9d21ec9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Accenture',\n",
       " 'Accenture',\n",
       " 'Mphasis',\n",
       " 'CitiusTech',\n",
       " 'ZS Associates',\n",
       " 'Tech Mahindra',\n",
       " 'Boston Consulting Group',\n",
       " 'IBM',\n",
       " 'Walmart',\n",
       " 'Wipro']"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Searching for all job titles using XPATH of Titles and storing them in job titles\n",
    "title_tag=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tag[0:10]:\n",
    "    title=i.text\n",
    "    job_title2.append(title)\n",
    "job_title2[0:10]\n",
    "\n",
    "#Searching for all Locations using its XPATH and storing them in job locations\n",
    "location_tag=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in location_tag[0:10]:\n",
    "    job_location2.append(i.text)\n",
    "job_location2[0:10]  \n",
    "\n",
    "\n",
    "#Searching for all Company names using xpath and storing them into company names.\n",
    "company_tag=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tag[0:10]:\n",
    "    company_name2.append(i.text)\n",
    "company_name2[0:10]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "f1c9f4da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science Specialist</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science Manager</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mongodb Database Administrator, Maria DB or Ca...</td>\n",
       "      <td>Bangalore/Bengaluru, Hyderabad/Secunderabad, P...</td>\n",
       "      <td>Mphasis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Assistant Manager - Data Science</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Pune</td>\n",
       "      <td>CitiusTech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, New Delhi, Pune, Gurgaon/...</td>\n",
       "      <td>ZS Associates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Hyderabad/Secunderabad, P...</td>\n",
       "      <td>Tech Mahindra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, New Delhi, Chennai</td>\n",
       "      <td>Boston Consulting Group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist: Artificial Intelligence</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>IBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist - Computer Vision</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Walmart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Pune, Chennai</td>\n",
       "      <td>Wipro</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Job title  \\\n",
       "1                             Data Science Specialist   \n",
       "2                                Data Science Manager   \n",
       "3   Mongodb Database Administrator, Maria DB or Ca...   \n",
       "4                    Assistant Manager - Data Science   \n",
       "5                                      Data Scientist   \n",
       "6                                      Data Scientist   \n",
       "7                               Senior Data Scientist   \n",
       "8             Data Scientist: Artificial Intelligence   \n",
       "9                    Data Scientist - Computer Vision   \n",
       "10                              Senior Data Scientist   \n",
       "\n",
       "                                         Job Location             Company name  \n",
       "1   Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...                Accenture  \n",
       "2   Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...                Accenture  \n",
       "3   Bangalore/Bengaluru, Hyderabad/Secunderabad, P...                  Mphasis  \n",
       "4                   Bangalore/Bengaluru, Mumbai, Pune               CitiusTech  \n",
       "5   Bangalore/Bengaluru, New Delhi, Pune, Gurgaon/...            ZS Associates  \n",
       "6   Bangalore/Bengaluru, Hyderabad/Secunderabad, P...            Tech Mahindra  \n",
       "7     Bangalore/Bengaluru, Mumbai, New Delhi, Chennai  Boston Consulting Group  \n",
       "8                                 Bangalore/Bengaluru                      IBM  \n",
       "9                                 Bangalore/Bengaluru                  Walmart  \n",
       "10                 Bangalore/Bengaluru, Pune, Chennai                    Wipro  "
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Presenting the data in form of Data Frame using Pandas\n",
    "df=pd.DataFrame({\"Job title\":job_title2[0:10],\"Job Location\":job_location2[0:10],\"Company name\":company_name2[0:10]})\n",
    "df.index+=1     \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07fdd45",
   "metadata": {},
   "source": [
    "Q3: In this question you have to scrape data using the filters available on the webpage as shown below:\n",
    "\n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company name, experience required. \n",
    "The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "5. Then scrape the data for the first 10 jobs results you get.\n",
    "6. Finally create a dataframe of the scraped data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "979ba21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting webdriver\n",
    "driver=webdriver.Chrome(r\"D:\\webdriver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "4d16606b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sending URL\n",
    "driver.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "8cd88e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sending keys Data Scientist Using Class Name\n",
    "desi=driver.find_element(By.CLASS_NAME,\"suggestor-input \")\n",
    "desi.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "88f472c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on Search Button\n",
    "search=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[6]\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "edae6c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting Location filter\n",
    "locfilt=driver.find_element(By.XPATH,\"/html/body/div[1]/div[4]/div/section[1]/div[2]/div[5]/div[2]/div[3]\")\n",
    "locfilt.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "f4937389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the salary filter\n",
    "salfilt=driver.find_element(By.XPATH,\"/html/body/div[1]/div[4]/div/section[1]/div[2]/div[6]/div[2]/div[2]/label/p/span[1]\")\n",
    "salfilt.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "c716db00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty lists to store values\n",
    "job_title3=[]\n",
    "job_location3=[]\n",
    "company_name3=[]\n",
    "experience_required3=[]\n",
    "salary3=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "be176a44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Not disclosed',\n",
       " 'Not disclosed',\n",
       " '3,00,000 - 4,50,000 PA.',\n",
       " 'Not disclosed',\n",
       " 'Not disclosed',\n",
       " 'Not disclosed',\n",
       " 'Not disclosed',\n",
       " '5,00,000 - 12,00,000 PA.',\n",
       " 'Not disclosed',\n",
       " 'Not disclosed']"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Searching the titles, location,company name,experience, salary using their xpaths and storing them in their respective empty lists\n",
    "title_tag=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tag[0:10]:\n",
    "    title=i.text\n",
    "    job_title3.append(title)\n",
    "job_title3[0:10]\n",
    "\n",
    "\n",
    "location_tag=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in location_tag[0:10]:\n",
    "    job_location3.append(i.text)\n",
    "job_location3[0:10]  \n",
    "\n",
    "\n",
    "\n",
    "company_tag=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tag[0:10]:\n",
    "    company_name3.append(i.text)\n",
    "company_name3[0:10]\n",
    "\n",
    "\n",
    "experienced_tag=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "for i in experienced_tag:\n",
    "    experience_required3.append(i.text)\n",
    "experience_required3[0:10] \n",
    "\n",
    "\n",
    "salary_tag=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi salary\"]')\n",
    "for i in salary_tag:\n",
    "    salary3.append(i.text)\n",
    "salary3[0:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "8f5612b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company name</th>\n",
       "      <th>Experience required</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Noida(Sector-59 Noida)\\n(WFH during Covid)</td>\n",
       "      <td>R Systems International</td>\n",
       "      <td>7-10 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist - Engine Algorithm</td>\n",
       "      <td>Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida, Nagpur, Bangalore/Bengaluru</td>\n",
       "      <td>GlobalLogic</td>\n",
       "      <td>8-10 Yrs</td>\n",
       "      <td>3,00,000 - 4,50,000 PA.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DigitalBCG GAMMA Data Scientist</td>\n",
       "      <td>New Delhi, Bangalore/Bengaluru</td>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Activation Specialist - Adobe Target</td>\n",
       "      <td>Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...</td>\n",
       "      <td>Okda Solutions</td>\n",
       "      <td>7-10 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>IHS Markit</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Optum</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist / Chat-bot Developer</td>\n",
       "      <td>New Delhi, Bangalore/Bengaluru, Mumbai (All Ar...</td>\n",
       "      <td>Big Seo Buzz</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "      <td>5,00,000 - 12,00,000 PA.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist - Mumbai - Immediate Joiner Req...</td>\n",
       "      <td>Delhi / NCR, Mumbai, New Delhi</td>\n",
       "      <td>HueCanvas Consulting</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>NGI Ventures</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Job title  \\\n",
       "1                                 Lead Data Scientist   \n",
       "2                   Data Scientist - Engine Algorithm   \n",
       "3                                      Data Scientist   \n",
       "4                     DigitalBCG GAMMA Data Scientist   \n",
       "5           Data Activation Specialist - Adobe Target   \n",
       "6                                      Data Scientist   \n",
       "7                                      Data Scientist   \n",
       "8                 Data Scientist / Chat-bot Developer   \n",
       "9   Data Scientist - Mumbai - Immediate Joiner Req...   \n",
       "10                                     Data Scientist   \n",
       "\n",
       "                                         Job Location  \\\n",
       "1          Noida(Sector-59 Noida)\\n(WFH during Covid)   \n",
       "2   Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...   \n",
       "3                  Noida, Nagpur, Bangalore/Bengaluru   \n",
       "4                      New Delhi, Bangalore/Bengaluru   \n",
       "5   Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...   \n",
       "6                                    Gurgaon/Gurugram   \n",
       "7                                    Gurgaon/Gurugram   \n",
       "8   New Delhi, Bangalore/Bengaluru, Mumbai (All Ar...   \n",
       "9                      Delhi / NCR, Mumbai, New Delhi   \n",
       "10                                              Noida   \n",
       "\n",
       "               Company name Experience required                    Salary  \n",
       "1   R Systems International            7-10 Yrs             Not disclosed  \n",
       "2              Primo Hiring             1-3 Yrs             Not disclosed  \n",
       "3               GlobalLogic            8-10 Yrs   3,00,000 - 4,50,000 PA.  \n",
       "4   Boston Consulting Group             2-5 Yrs             Not disclosed  \n",
       "5            Okda Solutions            7-10 Yrs             Not disclosed  \n",
       "6                IHS Markit             3-6 Yrs             Not disclosed  \n",
       "7                     Optum             2-7 Yrs             Not disclosed  \n",
       "8              Big Seo Buzz             3-7 Yrs  5,00,000 - 12,00,000 PA.  \n",
       "9      HueCanvas Consulting             2-7 Yrs             Not disclosed  \n",
       "10             NGI Ventures             0-5 Yrs             Not disclosed  "
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Data frame using Pandas\n",
    "df=pd.DataFrame({\"Job title\":job_title3[0:10],\"Job Location\":job_location3[0:10],\"Company name\":company_name3[0:10],\"Experience required\":experience_required3[0:10],\"Salary\":salary3[0:10]})\n",
    "df.index+=1     \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256a294f",
   "metadata": {},
   "source": [
    "Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "\n",
    "The attributes which you have to scrape is ticked marked in the below image.\n",
    "To scrape the data you have to go through following steps:\n",
    "1. Go to Flipkart webpage by url : https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search field where “search for products, brands and more” is written and \n",
    "click the search icon\n",
    "3. After that you will reach to the page having a lot of sunglasses. From this page you can scrap the \n",
    "required data as usual.\n",
    "4. After scraping data from the first page, go to the “Next” Button at the bottom other page , then \n",
    "click on it.\n",
    "5. Now scrape data from this page as usual\n",
    "6. Repeat this until you get data for 100 sunglasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "8f3adb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting driver\n",
    "driver=webdriver.Chrome(r\"D:\\webdriver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "78dfeef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sending url\n",
    "driver.get('http://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "efb36d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Closing the login page\n",
    "close1=driver.find_element(By.XPATH,'/html/body/div[2]/div/div/button')\n",
    "close1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "d2a27ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sending keys sunglasses in search bar using xpath\n",
    "finds=driver.find_element(By.XPATH,'/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input')\n",
    "finds.send_keys('sunglasses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "302a5f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking n the search button\n",
    "search=driver.find_element(By.XPATH,'/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "bd5cf9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty lists to store values \n",
    "brand=[]\n",
    "pda=[]\n",
    "price=[]\n",
    "discount=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "612b6cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a loop for searching through multiple pages and searching with the help of xpath and storing the brand description \n",
    "# price and discounts in lists and also using time.sleep function so our code starts itearating 3 seconds late so our webpage\n",
    "# can be loaded successfully\n",
    "s=0\n",
    "e=4\n",
    "for page in range(s,e):\n",
    "    brnd=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    for i in brnd:\n",
    "        brand.append(i.text)\n",
    "    nextbutton=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    nextbutton.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "9ae15e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "s=0\n",
    "e=4\n",
    "for page in range(s,e):\n",
    "    pdd=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "    for i in pdd:\n",
    "        pda.append(i.text)\n",
    "    nextbutton=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    nextbutton.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "5107da2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "s=0\n",
    "e=4\n",
    "for page in range(s,e):\n",
    "    pr=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "    for i in pr:\n",
    "        price.append(i.text)\n",
    "    nextbutton=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    nextbutton.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "928f1356",
   "metadata": {},
   "outputs": [],
   "source": [
    "s=0\n",
    "e=4\n",
    "for page in range(s,e):\n",
    "    disc=driver.find_elements(By.XPATH,'//div[@class=\"_3Ay6Sb\"]')\n",
    "    for i in disc:\n",
    "        discount.append(i.text)\n",
    "    nextbutton=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    nextbutton.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "194126f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Produsct decription</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection Aviator Sunglasses (55)</td>\n",
       "      <td>₹649</td>\n",
       "      <td>74% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection, Gradient Round Sunglasses (Free...</td>\n",
       "      <td>₹399</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹799</td>\n",
       "      <td>20% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DEIXELS</td>\n",
       "      <td>Polarized, UV Protection, Riding Glasses Wayfa...</td>\n",
       "      <td>₹249</td>\n",
       "      <td>58% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SHAAH COLLECTIONS</td>\n",
       "      <td>UV Protection Round Sunglasses (54)</td>\n",
       "      <td>₹179</td>\n",
       "      <td>86% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Singco India</td>\n",
       "      <td>UV Protection Cat-eye Sunglasses (56)</td>\n",
       "      <td>₹486</td>\n",
       "      <td>75% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Cat-eye S...</td>\n",
       "      <td>₹599</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>MODE</td>\n",
       "      <td>UV Protection Aviator Sunglasses (Free Size)</td>\n",
       "      <td>₹179</td>\n",
       "      <td>77% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>New Specs</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹264</td>\n",
       "      <td>89% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>NuVew</td>\n",
       "      <td>UV Protection Rectangular, Retro Square Sungla...</td>\n",
       "      <td>₹398</td>\n",
       "      <td>82% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Brand                                Produsct decription  \\\n",
       "1       ROZZETTA CRAFT              UV Protection Aviator Sunglasses (55)   \n",
       "2       ROZZETTA CRAFT  UV Protection, Gradient Round Sunglasses (Free...   \n",
       "3             Fastrack      UV Protection Wayfarer Sunglasses (Free Size)   \n",
       "4              DEIXELS  Polarized, UV Protection, Riding Glasses Wayfa...   \n",
       "5    SHAAH COLLECTIONS                UV Protection Round Sunglasses (54)   \n",
       "..                 ...                                                ...   \n",
       "96        Singco India              UV Protection Cat-eye Sunglasses (56)   \n",
       "97       VINCENT CHASE  by Lenskart Polarized, UV Protection Cat-eye S...   \n",
       "98                MODE       UV Protection Aviator Sunglasses (Free Size)   \n",
       "99           New Specs   UV Protection Rectangular Sunglasses (Free Size)   \n",
       "100              NuVew  UV Protection Rectangular, Retro Square Sungla...   \n",
       "\n",
       "    Price Discount  \n",
       "1    ₹649  74% off  \n",
       "2    ₹399  80% off  \n",
       "3    ₹799  20% off  \n",
       "4    ₹249  58% off  \n",
       "5    ₹179  86% off  \n",
       "..    ...      ...  \n",
       "96   ₹486  75% off  \n",
       "97   ₹599  70% off  \n",
       "98   ₹179  77% off  \n",
       "99   ₹264  89% off  \n",
       "100  ₹398  82% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using pandas representing the data in DATA FRAME\n",
    "df=pd.DataFrame({\"Brand\":brand[0:100],\"Produsct decription\":pda[0:100],\"Price\":price[0:100],\"Discount\":discount[0:100]})\n",
    "df.index+=1\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635b48a2",
   "metadata": {},
   "source": [
    "Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.flipkart.com/\n",
    "2. Enter “iphone 11” in “Search” field . \n",
    "3. Then click the search button.\n",
    "You will reach to the below shown webpage .\n",
    "As shown in the above page you have to scrape the tick marked attributes.These are:\n",
    "1. Rating\n",
    "2. Review summary\n",
    "3. Full review\n",
    "4. You have to scrape this data for first 100 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "376bed1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting with Driver\n",
    "driver=webdriver.Chrome(r\"D:\\webdriver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "5bcd5a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sending url\n",
    "driver.get('http://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "19df5d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Closing the login window\n",
    "close=driver.find_element(By.XPATH,'/html/body/div[2]/div/div/button')\n",
    "close.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "c6ef9726",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sending iphone 11 in the search box\n",
    "finds=driver.find_element(By.XPATH,'/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input')\n",
    "finds.send_keys('iphone 11')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "ae7a71e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking the search box\n",
    "search=driver.find_element(By.XPATH,'/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "72ca01bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking the first iphone 11 in results\n",
    "geet=driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[2]/div/div/div/a')\n",
    "geet.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "fef6229b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting the driver to new pop in page\n",
    "driver.get('https://www.flipkart.com/apple-iphone-11-black-128-gb/p/itm8244e8d955aba?pid=MOBFWQ6BKRYBP5X8&lid=LSTMOBFWQ6BKRYBP5X8IBG6BS&marketplace=FLIPKART&q=iphone+11&store=tyy%2F4io&srno=s_1_1&otracker=search&otracker1=search&iid=39344aac-a28b-4e14-a7a2-f5316631be91.MOBFWQ6BKRYBP5X8.SEARCH&ssid=d0opa6149s0000001664692162582&qH=f6cdfdaa9f3c23f3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "68c69bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking the all Reviews button\n",
    "ar=driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[9]/div[7]/div/a/div')\n",
    "ar.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "1dfbbccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty lists to store values\n",
    "st=0\n",
    "en=10\n",
    "rating=[]\n",
    "rs=[]\n",
    "fr=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "cf7d1c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a loop for searching through multiple pages and searching with the help of xpath and storing the rating review summary and ful review\n",
    "# in lists and also using time.sleep function so our code starts itearating 3 seconds late so our webpage\n",
    "# can be loaded successfully\n",
    "for page in range(st,en):\n",
    "    ro=driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "    for i in ro:\n",
    "         rs.append(i.text)\n",
    "    nextpage=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    nextpage.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "4e06f986",
   "metadata": {},
   "outputs": [],
   "source": [
    "for page in range(st,en):\n",
    "    fro=driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]')\n",
    "    for i in fro:\n",
    "        fr.append(i.text.replace('\\n',\"\"))\n",
    "    nextpage=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    nextpage.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "90e287b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for page in range(st,en):\n",
    "    rt=driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "    for i in rt:\n",
    "         rating.append(i.text)\n",
    "    nextpage=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    nextpage.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "ea51a8d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review summary</th>\n",
       "      <th>Full Review</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Value-for-money</td>\n",
       "      <td>I'm Really happy with the productDelivery was ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Value for money❤️❤️Its awesome mobile phone in...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Pretty good</td>\n",
       "      <td>I was using Iphone 6s and also Oneplus 6t. Bot...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>Amazing camera quality as expected, battery al...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Smooth like butter, camera like fantabulous, s...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Iphone is just awesome.. battery backup is ver...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Review summary                                        Full Review  \\\n",
       "1         Simply awesome  Really satisfied with the Product I received.....   \n",
       "2        Value-for-money  I'm Really happy with the productDelivery was ...   \n",
       "3       Perfect product!  Amazing phone with great cameras and better ba...   \n",
       "4    Best in the market!  Great iPhone very snappy experience as apple k...   \n",
       "5      Worth every penny  Previously I was using one plus 3t it was a gr...   \n",
       "..                   ...                                                ...   \n",
       "96      Perfect product!  Value for money❤️❤️Its awesome mobile phone in...   \n",
       "97           Pretty good  I was using Iphone 6s and also Oneplus 6t. Bot...   \n",
       "98    Highly recommended  Amazing camera quality as expected, battery al...   \n",
       "99     Worth every penny  Smooth like butter, camera like fantabulous, s...   \n",
       "100     Perfect product!  Iphone is just awesome.. battery backup is ver...   \n",
       "\n",
       "    Rating  \n",
       "1        5  \n",
       "2        4  \n",
       "3        5  \n",
       "4        5  \n",
       "5        5  \n",
       "..     ...  \n",
       "96       5  \n",
       "97       4  \n",
       "98       5  \n",
       "99       5  \n",
       "100      5  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Data Frame using pandas\n",
    "df=pd.DataFrame({'Review summary':rs[0:100],'Full Review':fr[0:100],'Rating':rating[0:100]})\n",
    "df.index+=1\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3401d3f0",
   "metadata": {},
   "source": [
    "Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the \n",
    "search field.\n",
    "You have to scrape 4 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "As shown in the below image, you have to scrape the tick marked attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "21ea45be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connecting driver\n",
    "driver=webdriver.Chrome(r\"D:\\webdriver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "b8b74e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sending Url\n",
    "driver.get('http://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "08217067",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Closing login window\n",
    "close=driver.find_element(By.XPATH,'/html/body/div[2]/div/div/button')\n",
    "close.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "0b99f672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sending sneakers in search bar\n",
    "finde=driver.find_element(By.XPATH,'/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input')\n",
    "finde.send_keys('Sneakers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "00b4a8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on the search bar\n",
    "search=driver.find_element(By.XPATH,'/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "fb93eb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty lists to store values\n",
    "brands=[]\n",
    "descr=[]\n",
    "prices=[]\n",
    "discounts=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "d9e9c440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a loop for searching through multiple pages and searching with the help of xpath and storing the brand,description price and discounts\n",
    "# in lists and also using time.sleep function so our code starts itearating 3 seconds late so our webpage\n",
    "# can be loaded successfully\n",
    "s=0\n",
    "e=3\n",
    "for page in range(s,e):\n",
    "    brndd=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    for i in brndd:\n",
    "        brands.append(i.text)\n",
    "    nextbutton=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    nextbutton.click()\n",
    "    time.sleep(3)\n",
    "    brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "1934baca",
   "metadata": {},
   "outputs": [],
   "source": [
    "s=0\n",
    "e=3\n",
    "for page in range(s,e):\n",
    "    de=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "    for i in de:\n",
    "        descr.append(i.text)\n",
    "    nextbutton=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    nextbutton.click()\n",
    "    time.sleep(3)\n",
    "    descr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "3cb7d28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "s=0\n",
    "e=3\n",
    "for page in range(s,e):\n",
    "    p=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "    for i in p:\n",
    "        prices.append(i.text)\n",
    "    nextbutton=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    nextbutton.click()\n",
    "    time.sleep(3)\n",
    "    prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "5b1c60f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "s=0\n",
    "e=3\n",
    "for page in range(s,e):\n",
    "    d=driver.find_elements(By.XPATH,'//div[@class=\"_3Ay6Sb\"]')\n",
    "    for i in d:\n",
    "        discounts.append(i.text)\n",
    "    nextbutton=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    nextbutton.click()\n",
    "    time.sleep(3)\n",
    "    discounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "363bf37d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RapidBox</td>\n",
       "      <td>2 Combo Sneaker Shoes Sneakers For Men</td>\n",
       "      <td>₹590</td>\n",
       "      <td>74% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mzzideko</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹549</td>\n",
       "      <td>63% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹470</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Labbin</td>\n",
       "      <td>Casual Sneakers Canvas Shoes For Men Sneakers ...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RED TAPE</td>\n",
       "      <td>Latest Exclusive Affordable Collection of Tren...</td>\n",
       "      <td>₹1,499</td>\n",
       "      <td>45% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>frento</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹599</td>\n",
       "      <td>65% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>World Wear Footwear</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹289</td>\n",
       "      <td>74% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Deals4you</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹413</td>\n",
       "      <td>54% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ASTEROID</td>\n",
       "      <td>Classic Sneakers For Men</td>\n",
       "      <td>₹499</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Numenzo</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹2,799</td>\n",
       "      <td>71% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Brand                                Product description  \\\n",
       "1               RapidBox             2 Combo Sneaker Shoes Sneakers For Men   \n",
       "2               Mzzideko                                   Sneakers For Men   \n",
       "3                 BRUTON                                   Sneakers For Men   \n",
       "4                 Labbin  Casual Sneakers Canvas Shoes For Men Sneakers ...   \n",
       "5               RED TAPE  Latest Exclusive Affordable Collection of Tren...   \n",
       "..                   ...                                                ...   \n",
       "96                frento                                   Sneakers For Men   \n",
       "97   World Wear Footwear                                   Sneakers For Men   \n",
       "98             Deals4you                                   Sneakers For Men   \n",
       "99              ASTEROID                           Classic Sneakers For Men   \n",
       "100              Numenzo                                   Sneakers For Men   \n",
       "\n",
       "      Price Discount  \n",
       "1      ₹590  74% off  \n",
       "2      ₹549  63% off  \n",
       "3      ₹470  50% off  \n",
       "4      ₹499  50% off  \n",
       "5    ₹1,499  45% off  \n",
       "..      ...      ...  \n",
       "96     ₹599  65% off  \n",
       "97     ₹289  74% off  \n",
       "98     ₹413  54% off  \n",
       "99     ₹499  50% off  \n",
       "100  ₹2,799  71% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Data Frame using pandas\n",
    "df=pd.DataFrame({'Brand':brands[0:100],'Product description':descr[0:100],'Price':prices[0:100],'Discount':discounts[0:100]})\n",
    "df.index+=1\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2ac26c",
   "metadata": {},
   "source": [
    " Go to the link - https://www.myntra.com/shoes\n",
    "Set second Price filter and Color filter to “Black”, as shown in the below image.\n",
    "And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe \n",
    "description, price of the shoe as shown in the below image.\n",
    "Note: Applying the filter and scraping the data, everything should be done through code only and there \n",
    "should not be any manual step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "bc07c01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connenting driver\n",
    "driver=webdriver.Chrome(r\"D:\\webdriver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "d2be82ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sending url\n",
    "driver.get('https://www.myntra.com/shoes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "0d586f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting price filter\n",
    "pricefil=driver.find_element(By.XPATH,'/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label')\n",
    "pricefil.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "c3db0b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting color filter\n",
    "colfil=driver.find_element(By.XPATH,'/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]/label')\n",
    "colfil.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "e8a42380",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty lists to store values\n",
    "Brand=[]\n",
    "Description=[]\n",
    "Price=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "da7a5f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a loop for searching through multiple pages and searching with the help of xpath and storing the brand,description, price\n",
    "# in lists and also using time.sleep function so our code starts itearating 3 seconds late so our webpage\n",
    "# can be loaded successfully\n",
    "start=0\n",
    "end=2\n",
    "for page in range(start,end):\n",
    "    bd=driver.find_elements(By.XPATH,'//h3[@class=\"product-brand\"]')\n",
    "    for i in bd:\n",
    "        Brand.append(i.text)\n",
    "    nextpage=driver.find_element(By.XPATH,'//li[@class=\"pagination-next\"]')\n",
    "    nextpage.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "01e37a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=0\n",
    "end=2\n",
    "for page in range(start,end):\n",
    "    dd=driver.find_elements(By.XPATH,'//h4[@class=\"product-product\"]')\n",
    "    for i in dd:\n",
    "        Description.append(i.text)\n",
    "    nextpage=driver.find_element(By.XPATH,'//li[@class=\"pagination-next\"]')\n",
    "    nextpage.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "21af9d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=0\n",
    "end=2\n",
    "for page in range(start,end):\n",
    "    pp=driver.find_elements(By.XPATH,'//div[@class=\"product-price\"]')\n",
    "    for i in pp:\n",
    "        Price.append(i.text)\n",
    "    nextpage=driver.find_element(By.XPATH,'//li[@class=\"pagination-next\"]')\n",
    "    nextpage.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "ce24ec82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADIDAS</td>\n",
       "      <td>Men MAX ELITE Running Shoes</td>\n",
       "      <td>Rs. 6999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td></td>\n",
       "      <td>Rs. 8550Rs. 9500(10% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADIDAS</td>\n",
       "      <td>Men Solid Leather Formal Derbys</td>\n",
       "      <td>Rs. 11250Rs. 12500(10% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Skechers</td>\n",
       "      <td>Women Leather Horsebit Loafers</td>\n",
       "      <td>Rs. 8550Rs. 9500(10% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Men Solid Leather Formal Monks</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Tommy Hilfiger</td>\n",
       "      <td>Men MEERNO Sneakers</td>\n",
       "      <td>Rs. 9099Rs. 12999(30% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Men Perforations Leather Loafers</td>\n",
       "      <td>Rs. 8999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Men Textured Leather Loafers</td>\n",
       "      <td>Rs. 8075Rs. 9500(15% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>fitflop</td>\n",
       "      <td>Men Textured Leather Loafers</td>\n",
       "      <td>Rs. 7199Rs. 11999(40% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Men Woven Design Sneakers</td>\n",
       "      <td>Rs. 7149Rs. 10999(35% OFF)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Brand               Product Description  \\\n",
       "1            ADIDAS       Men MAX ELITE Running Shoes   \n",
       "2      UNDER ARMOUR                                     \n",
       "3            ADIDAS   Men Solid Leather Formal Derbys   \n",
       "4          Skechers    Women Leather Horsebit Loafers   \n",
       "5      UNDER ARMOUR    Men Solid Leather Formal Monks   \n",
       "..              ...                               ...   \n",
       "96   Tommy Hilfiger               Men MEERNO Sneakers   \n",
       "97             ALDO  Men Perforations Leather Loafers   \n",
       "98             ALDO      Men Textured Leather Loafers   \n",
       "99          fitflop      Men Textured Leather Loafers   \n",
       "100    UNDER ARMOUR         Men Woven Design Sneakers   \n",
       "\n",
       "                           Price  \n",
       "1                       Rs. 6999  \n",
       "2      Rs. 8550Rs. 9500(10% OFF)  \n",
       "3    Rs. 11250Rs. 12500(10% OFF)  \n",
       "4      Rs. 8550Rs. 9500(10% OFF)  \n",
       "5                       Rs. 7999  \n",
       "..                           ...  \n",
       "96    Rs. 9099Rs. 12999(30% OFF)  \n",
       "97                      Rs. 8999  \n",
       "98     Rs. 8075Rs. 9500(15% OFF)  \n",
       "99    Rs. 7199Rs. 11999(40% OFF)  \n",
       "100   Rs. 7149Rs. 10999(35% OFF)  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating Data Frame using Pandas\n",
    "df=pd.DataFrame({'Brand':Brand,'Product Description':Description,'Price':Price})\n",
    "df.index+=1\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c262604",
   "metadata": {},
   "source": [
    "Q8: Go to webpage https://www.amazon.in/\n",
    "Enter “Laptop” in the search field and then click the search icon.\n",
    "Then set CPU Type filter to “Intel Core i7” as shown in the below image:\n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributesfor each laptop:\n",
    "1. Title\n",
    "2. Ratings\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "ee66f3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting Driver\n",
    "driver=webdriver.Chrome(r\"D:\\webdriver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "4f3d86b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sending Url\n",
    "driver.get('https://www.amazon.in/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "6afcc91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sending Laptop in the search box\n",
    "key=driver.find_element(By.XPATH,'/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input')\n",
    "key.send_keys('LAPTOP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "75fd40d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CLicking the search button\n",
    "search=driver.find_element(By.XPATH,'/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div/span/input')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "403ef2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting the CPU type filter\n",
    "ctype=driver.find_element(By.XPATH,'/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/div/div/div[6]/ul[5]/li[10]/span/a/span')\n",
    "ctype.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "8381ba0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty lists of titles,ratings and prices\n",
    "titles=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "c1ff9d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ratings=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "e80fd3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Prices=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "6db02882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a loop for  and searching with the help of xpath and storing the titles,ratings and price in respective Lists\n",
    "tt=driver.find_elements(By.XPATH,'//h2[@class=\"a-size-mini a-spacing-none a-color-base s-line-clamp-4\"]')\n",
    "for i in tt:\n",
    "    titles.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "f1181779",
   "metadata": {},
   "outputs": [],
   "source": [
    "rr=driver.find_elements(By.XPATH,'//i[@class=\"a-icon a-icon-star-small a-star-small-4 aok-align-bottom\"]')\n",
    "for i in rr:\n",
    "    Ratings.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "d4d164e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr=driver.find_elements(By.XPATH,'//span[@class=\"a-price-whole\"]')\n",
    "for i in pr:\n",
    "    Prices.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "0a35dd9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56, 20, 56)"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Prices),len(Ratings),len(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "21d4d4e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fujitsu UH-X 11th Gen Intel Core i7 13.3\" FHD ...</td>\n",
       "      <td></td>\n",
       "      <td>1,00,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fujitsu UH-X 12th Gen Intel Evo Core i7 13.3 i...</td>\n",
       "      <td></td>\n",
       "      <td>99,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fujitsu UH-X 12th Gen Intel Evo Core i7 13.3 i...</td>\n",
       "      <td></td>\n",
       "      <td>99,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASUS Vivobook 15, 15.6-inch (39.62 cms) FHD, I...</td>\n",
       "      <td></td>\n",
       "      <td>77,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lenovo IdeaPad Slim 5 Intel Core i7 12th Gen 1...</td>\n",
       "      <td></td>\n",
       "      <td>79,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Acer Nitro 5 Core i7 11th Gen 15.6\" (39.62cms)...</td>\n",
       "      <td></td>\n",
       "      <td>89,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lenovo IdeaPad Flex 5 Intel Core i7 11th Gen 1...</td>\n",
       "      <td></td>\n",
       "      <td>74,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HP Pavilion Plus, 12th Gen Intel Core i7 16GB ...</td>\n",
       "      <td></td>\n",
       "      <td>86,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ASUS Zenbook 13 OLED, 13.3-inch (33.78 cms) FH...</td>\n",
       "      <td></td>\n",
       "      <td>93,290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(Renewed) Lenovo Intel 6th Gen Core i7 12.5 In...</td>\n",
       "      <td></td>\n",
       "      <td>24,964</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title Ratings     Price\n",
       "1   Fujitsu UH-X 11th Gen Intel Core i7 13.3\" FHD ...          1,00,000\n",
       "2   Fujitsu UH-X 12th Gen Intel Evo Core i7 13.3 i...            99,990\n",
       "3   Fujitsu UH-X 12th Gen Intel Evo Core i7 13.3 i...            99,990\n",
       "4   ASUS Vivobook 15, 15.6-inch (39.62 cms) FHD, I...            77,990\n",
       "5   Lenovo IdeaPad Slim 5 Intel Core i7 12th Gen 1...            79,990\n",
       "6   Acer Nitro 5 Core i7 11th Gen 15.6\" (39.62cms)...            89,990\n",
       "7   Lenovo IdeaPad Flex 5 Intel Core i7 11th Gen 1...            74,990\n",
       "8   HP Pavilion Plus, 12th Gen Intel Core i7 16GB ...            86,990\n",
       "9   ASUS Zenbook 13 OLED, 13.3-inch (33.78 cms) FH...            93,290\n",
       "10  (Renewed) Lenovo Intel 6th Gen Core i7 12.5 In...            24,964"
      ]
     },
     "execution_count": 499,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({'Title':titles[0:10],'Ratings':Ratings[0:10],'Price':Prices[0:10]})\n",
    "df.index+=1\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2954cb6a",
   "metadata": {},
   "source": [
    "Q10: Write a python program to scrape the salary data for Data Scientist designation.\n",
    "You have to scrape Company name, Number of salaries, Average salary, Minsalary, Max Salary. \n",
    "The above task will be, done as shown in the below steps:\n",
    "1. First get the webpage https://www.ambitionbox.com/\n",
    "2. Click on the salaries option as shown in the image.\n",
    "ASSIGNMENT 2\n",
    "3. After reaching to the following webpage, In place of “Search Job Profile” enters “Data Scientist” and \n",
    "then click on “Data Scientist”.\n",
    "You have to scrape the data ticked in the above image.\n",
    "4. Scrape the data for the first 10 companies. Scrape the company name, total salary record, average \n",
    "salary, minimum salary, maximum salary, experience required.\n",
    "5. Store the data in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "8accd92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting driver\n",
    "driver=webdriver.Chrome(r\"D:\\webdriver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "id": "5797337e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sending url\n",
    "driver.get('https://www.ambitionbox.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "id": "1d80b081",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on salary tab\n",
    "sa=driver.find_element(By.XPATH,'/html/body/div/div/div/div[1]/header/nav/ul/li[3]/span')\n",
    "sa.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "id": "10a966b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on comapre salary popup\n",
    "sac=driver.find_element(By.XPATH,'/html/body/div/div/div/div[1]/header/nav/ul/li[3]/div/ul/li[1]/div/div[2]/a')\n",
    "sac.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "id": "165d6e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sending Data Scientist in search bar\n",
    "prof=driver.find_element(By.XPATH,'/html/body/div/div/div/main/section[1]/div[2]/div[1]/span/input')\n",
    "prof.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "id": "9bd65299",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on data scientist search bar\n",
    "search=driver.find_element(By.XPATH,'/html/body/div/div/div/main/section[1]/div[2]/div[1]/span/div/div/div[1]')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "id": "a6193423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing company name in cname\n",
    "cname=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "id": "c777c331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using for loop and Xpath storing cname and only taking the data at 0 index\n",
    "cn=driver.find_elements(By.XPATH,'//div[@class=\"company-info\"]')\n",
    "for i in cn:\n",
    "    cname.append(i.text.split('\\n')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "id": "eae4da99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing post\n",
    "post=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "b584edd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using for loop and Xpath storing in post\n",
    "po=driver.find_elements(By.XPATH,'//span[@class=\"jp\"]')\n",
    "for i in po:\n",
    "    post.append(i.text.split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "id": "49da7ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing in exp\n",
    "exp=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "0a27f096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using for loop and Xpath storing in exp and storing the data of 0 index\n",
    "ex=driver.find_elements(By.XPATH,'//div[@class=\"sbold-list-header\"]')\n",
    "for i in ex:\n",
    "    exp.append(i.text.split('(')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "id": "fbe901e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3-4 yrs experience ',\n",
       " '2-4 yrs experience ',\n",
       " '2-4 yrs experience ',\n",
       " '1-2 yrs experience ',\n",
       " '2-4 yrs experience ',\n",
       " '1 yr experience ',\n",
       " '2-4 yrs experience ',\n",
       " '4 yrs experience ',\n",
       " '4 yrs experience ',\n",
       " '3 yrs experience ']"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "id": "61e02e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing feedback on feeb\n",
    "feeb=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "id": "bc0d85fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using for loop and Xpath storing in feeb\n",
    "fv=driver.find_elements(By.XPATH,'//span[@class=\"datapoints\"]')\n",
    "for i in fv:\n",
    "    feeb.append(i.text.replace('(',\"\").replace(')',\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "id": "a584089c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating mini maxi and mm empty lists to store values\n",
    "mini=[]\n",
    "mm=[]\n",
    "maxi=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "dd14f1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using for loop and Xpath storing in mm\n",
    "mi=driver.find_elements(By.XPATH,'//div[@class=\"value body-medium\"]')\n",
    "for i in mi:\n",
    "    mm.append(i.text)\n",
    "# Now seperating the data based on even and odd indexes and storing it in mini and maxi\n",
    "for i in range(0,len(mm)):\n",
    "    if i%2:\n",
    "        maxi.append(mm[i])\n",
    "    else:\n",
    "        mini.append(mm[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "cf9857ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating empty list to store avg\n",
    "avg=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "id": "dfc1b08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "av=driver.find_elements(By.XPATH,'//p[@class=\"averageCtc\"]')\n",
    "for i in av:\n",
    "    avg.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "id": "431a00b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10, 10, 10, 25, 10)"
      ]
     },
     "execution_count": 581,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mini),len(maxi),len(avg),len(feeb),len(cname),len(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "410d1ff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Post</th>\n",
       "      <th>Minimum Salary</th>\n",
       "      <th>Maximum Salary</th>\n",
       "      <th>Average salary</th>\n",
       "      <th>Based on</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>[Data Scientist Salary]</td>\n",
       "      <td>₹ 25.0L</td>\n",
       "      <td>₹ 45.0L</td>\n",
       "      <td>₹ 32.2L</td>\n",
       "      <td>based on 24 salaries</td>\n",
       "      <td>3-4 yrs experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ab Inbev</td>\n",
       "      <td>[Data Scientist Salary]</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "      <td>₹ 26.0L</td>\n",
       "      <td>₹ 19.8L</td>\n",
       "      <td>based on 59 salaries</td>\n",
       "      <td>2-4 yrs experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Optum</td>\n",
       "      <td>[Data Scientist Salary]</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 22.6L</td>\n",
       "      <td>₹ 16.4L</td>\n",
       "      <td>based on 49 salaries</td>\n",
       "      <td>2-4 yrs experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ZS</td>\n",
       "      <td>[Data Scientist Salary]</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 22.0L</td>\n",
       "      <td>₹ 15.9L</td>\n",
       "      <td>based on 35 salaries</td>\n",
       "      <td>1-2 yrs experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>[Data Scientist Salary]</td>\n",
       "      <td>₹ 9.0L</td>\n",
       "      <td>₹ 23.0L</td>\n",
       "      <td>₹ 15.5L</td>\n",
       "      <td>based on 118 salaries</td>\n",
       "      <td>2-4 yrs experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sigmoid Analytics</td>\n",
       "      <td>[Data Scientist Salary]</td>\n",
       "      <td>₹ 12.7L</td>\n",
       "      <td>₹ 19.7L</td>\n",
       "      <td>₹ 14.7L</td>\n",
       "      <td>based on 10 salaries</td>\n",
       "      <td>1 yr experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tiger Analytics</td>\n",
       "      <td>[Data Scientist Salary]</td>\n",
       "      <td>₹ 9.0L</td>\n",
       "      <td>₹ 20.0L</td>\n",
       "      <td>₹ 14.6L</td>\n",
       "      <td>based on 70 salaries</td>\n",
       "      <td>2-4 yrs experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Legato Health Technologies</td>\n",
       "      <td>[Data Scientist Salary]</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 20.0L</td>\n",
       "      <td>₹ 14.5L</td>\n",
       "      <td>based on 11 salaries</td>\n",
       "      <td>4 yrs experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HSBC</td>\n",
       "      <td>[Data Scientist Salary]</td>\n",
       "      <td>₹ 12.0L</td>\n",
       "      <td>₹ 18.0L</td>\n",
       "      <td>₹ 14.0L</td>\n",
       "      <td>based on 10 salaries</td>\n",
       "      <td>4 yrs experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Tredence</td>\n",
       "      <td>[Data Scientist Salary]</td>\n",
       "      <td>₹ 8.8L</td>\n",
       "      <td>₹ 17.5L</td>\n",
       "      <td>₹ 13.9L</td>\n",
       "      <td>based on 14 salaries</td>\n",
       "      <td>3 yrs experience</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Company Name                     Post Minimum Salary  \\\n",
       "1                      Walmart  [Data Scientist Salary]        ₹ 25.0L   \n",
       "2                     Ab Inbev  [Data Scientist Salary]        ₹ 15.0L   \n",
       "3                        Optum  [Data Scientist Salary]        ₹ 11.0L   \n",
       "4                           ZS  [Data Scientist Salary]        ₹ 11.0L   \n",
       "5            Fractal Analytics  [Data Scientist Salary]         ₹ 9.0L   \n",
       "6            Sigmoid Analytics  [Data Scientist Salary]        ₹ 12.7L   \n",
       "7              Tiger Analytics  [Data Scientist Salary]         ₹ 9.0L   \n",
       "8   Legato Health Technologies  [Data Scientist Salary]        ₹ 11.0L   \n",
       "9                         HSBC  [Data Scientist Salary]        ₹ 12.0L   \n",
       "10                    Tredence  [Data Scientist Salary]         ₹ 8.8L   \n",
       "\n",
       "   Maximum Salary Average salary               Based on           Experience  \n",
       "1         ₹ 45.0L        ₹ 32.2L   based on 24 salaries  3-4 yrs experience   \n",
       "2         ₹ 26.0L        ₹ 19.8L   based on 59 salaries  2-4 yrs experience   \n",
       "3         ₹ 22.6L        ₹ 16.4L   based on 49 salaries  2-4 yrs experience   \n",
       "4         ₹ 22.0L        ₹ 15.9L   based on 35 salaries  1-2 yrs experience   \n",
       "5         ₹ 23.0L        ₹ 15.5L  based on 118 salaries  2-4 yrs experience   \n",
       "6         ₹ 19.7L        ₹ 14.7L   based on 10 salaries     1 yr experience   \n",
       "7         ₹ 20.0L        ₹ 14.6L   based on 70 salaries  2-4 yrs experience   \n",
       "8         ₹ 20.0L        ₹ 14.5L   based on 11 salaries    4 yrs experience   \n",
       "9         ₹ 18.0L        ₹ 14.0L   based on 10 salaries    4 yrs experience   \n",
       "10        ₹ 17.5L        ₹ 13.9L   based on 14 salaries    3 yrs experience   "
      ]
     },
     "execution_count": 582,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating data frame using pandas\n",
    "df=pd.DataFrame({\"Company Name\":cname[0:10],\"Post\":post,\"Minimum Salary\":mini,\"Maximum Salary\":maxi,\"Average salary\":avg,\"Based on\":feeb,\"Experience\":exp})\n",
    "df.index+=1\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2c83e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
